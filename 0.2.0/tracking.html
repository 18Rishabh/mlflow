
  

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MLflow Tracking &mdash; MLflow 0.1.0 documentation</title>
  
  
  
    <link rel="canonical" href="https://docs.databricks.com/tracking.html">
  
  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    

    

  
    
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-WXWDBL');</script>
      

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/css/algolia.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="MLflow 0.1.0 documentation" href="index.html"/>
        <link rel="next" title="MLflow Projects" href="/projects.html"/>
        <link rel="prev" title="Concepts" href="/concepts.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
      <a href="index.html" class="wy-nav-top-logo"><img src="_static/MLflow-logo-final-black.png" alt="MLFlow" /></a>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
  
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="index.html" class="main-navigation-home"><img src="_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="concepts.html">Concepts</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MLflow Tracking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#concepts">Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#where-runs-get-recorded">Where Runs Get Recorded</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logging-data-to-runs">Logging Data to Runs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-logging-functions">Basic Logging Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launching-multiple-runs-in-one-program">Launching Multiple Runs in One Program</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#organizing-runs-in-experiments">Organizing Runs in Experiments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tracking-ui">Tracking UI</a></li>
<li class="toctree-l2"><a class="reference internal" href="#querying-runs-programmatically">Querying Runs Programmatically</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-a-tracking-server">Running a Tracking Server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#storage">Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#networking">Networking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connecting-to-a-remote-server">Connecting to a Remote Server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="rest_api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/databricks/mlflow/blob/master/CONTRIBUTING.rst" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>MLflow Tracking</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="mlflow-tracking">
<span id="tracking"></span><h1>MLflow Tracking<a class="headerlink" href="#mlflow-tracking" title="Permalink to this headline"> </a></h1>
<p>The MLflow Tracking component lets you log and query experiments using either REST or Python.</p>
<div class="section" id="concepts">
<h2>Concepts<a class="headerlink" href="#concepts" title="Permalink to this headline"> </a></h2>
<p>MLflow Tracking is organized around the concept of <em>runs</em>, which are executions of some piece of
data science code. Each run records the following information:</p>
<dl class="docutils">
<dt>Code Version</dt>
<dd>Git commit used to execute the run, if it was executed from an <a class="reference internal" href="projects.html#projects"><span class="std std-ref">MLflow Project</span></a>.</dd>
<dt>Start &amp; End Time</dt>
<dd>Start and end time of the run</dd>
<dt>Source</dt>
<dd>Name of the file executed to launch the run, or the project name and entry point for the run
if the run was executed from an <a class="reference internal" href="projects.html#projects"><span class="std std-ref">MLflow Project</span></a>.</dd>
<dt>Parameters</dt>
<dd>Key-value input parameters of your choice. Both keys and values are strings.</dd>
<dt>Metrics</dt>
<dd>Key-value metrics where the value is numeric. Each metric can be updated throughout the
course of the run (for example, to track how your model’s loss function is converging), and
MLflow will record and let you visualize the metric’s full history.</dd>
<dt>Artifacts</dt>
<dd>Output files in any format. For example, you can record images (for example, PNGs), models
(for example, a pickled scikit-learn model) or even data files (for example, a
<a class="reference external" href="https://parquet.apache.org/">Parquet</a> file) as artifacts.</dd>
</dl>
<p>Runs can be recorded from anywhere you run your code through MLflow’s Python and REST APIs: for
example, you can record them in a standalone program, on a remote cloud machine, or in an
interactive notebook. If you record runs in an <a class="reference internal" href="projects.html#projects"><span class="std std-ref">MLflow Project</span></a>, however, MLflow
remembers the project URI and source version.</p>
<p>Finally, runs can optionally be organized into <em>experiments</em>, which group together runs for a
specific task. You can create an experiment via the <code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">experiments</span></code> CLI, with
<a class="reference internal" href="python_api/mlflow.html#mlflow.create_experiment" title="mlflow.create_experiment"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.create_experiment()</span></code></a>, or via the corresponding REST parameters. The MLflow UI and
API let you create and search for experiments.</p>
<p>Once your runs have been recorded, you can query them using the <a class="reference internal" href="#tracking-ui"><span class="std std-ref">Tracking UI</span></a> or the MLflow
API.</p>
</div>
<div class="section" id="where-runs-get-recorded">
<h2>Where Runs Get Recorded<a class="headerlink" href="#where-runs-get-recorded" title="Permalink to this headline"> </a></h2>
<p>MLflow runs can be recorded either locally in files or remotely to a tracking server.
By default, the MLflow Python API logs runs to files in an <code class="docutils literal notranslate"><span class="pre">mlruns</span></code> directory wherever you
ran your program. You can then run <code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">ui</span></code> to see the logged runs. Set the
<code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_URI</span></code> environment variable to a server’s URI or call
<a class="reference internal" href="python_api/mlflow.html#mlflow.set_tracking_uri" title="mlflow.set_tracking_uri"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.set_tracking_uri()</span></code></a> to log runs remotely.</p>
<p>You can also <a class="reference internal" href="#tracking-server"><span class="std std-ref">run your own tracking server</span></a> to record runs.</p>
</div>
<div class="section" id="logging-data-to-runs">
<h2>Logging Data to Runs<a class="headerlink" href="#logging-data-to-runs" title="Permalink to this headline"> </a></h2>
<p>You can log data to runs using either the MLflow REST API or the Python API. This section
shows the Python API, but there are corresponding REST APIs as well.</p>
<div class="section" id="basic-logging-functions">
<h3>Basic Logging Functions<a class="headerlink" href="#basic-logging-functions" title="Permalink to this headline"> </a></h3>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.set_tracking_uri" title="mlflow.set_tracking_uri"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.set_tracking_uri()</span></code></a> connects to a tracking URI. You can also set the
<cite>MLFLOW_TRACKING_URI</cite> environment variable to have MLflow find a URI from there. In both cases,
the URI can either be a HTTP/HTTPS URI for a remote server, or a local path to log data to a
directory. The URI defaults to <code class="docutils literal notranslate"><span class="pre">mlruns</span></code>.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.get_tracking_uri()</span></code> returns the current tracking URI.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.create_experiment" title="mlflow.create_experiment"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.create_experiment()</span></code></a> creates a new experiment and returns its ID. Runs can be
launched under the experiment by passing the experiment ID to <cite>mlflow.start_run</cite></p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.start_run" title="mlflow.start_run"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.start_run()</span></code></a> returns the currently active run (if one exists), or starts a new run
and returns a <a class="reference internal" href="python_api/mlflow.tracking.html#mlflow.tracking.ActiveRun" title="mlflow.tracking.ActiveRun"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.tracking.ActiveRun</span></code></a> object usable as a context manager for the
current run. You do not need to call <cite>start_run</cite> explicitly: calling one of the logging functions
with no active run will automatically start a new one.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.end_run" title="mlflow.end_run"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.end_run()</span></code></a> ends the currently active run, if any, taking an optional run status.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.active_run" title="mlflow.active_run"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.active_run()</span></code></a> returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.tracking.Run</span></code> object corresponding to the
currently active run, if any.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.log_param" title="mlflow.log_param"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.log_param()</span></code></a> logs a key-value parameter in the currently active run. The keys and
values are both strings.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.log_metric" title="mlflow.log_metric"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.log_metric()</span></code></a> logs a key-value metric. The value must always be a number. MLflow will
remember the history of values for each metric.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.log_artifact" title="mlflow.log_artifact"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.log_artifact()</span></code></a> logs a local file as an artifact, optionally taking an
<code class="docutils literal notranslate"><span class="pre">artifact_path</span></code> to place it in within the run’s artifact URI. Run artifacts can be organized into
directories, so you can place the artifact in a directory this way.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.log_artifacts" title="mlflow.log_artifacts"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.log_artifacts()</span></code></a> logs all the files in a given directory as artifacts, again taking
an optional <code class="docutils literal notranslate"><span class="pre">artifact_path</span></code>.</p>
<p><a class="reference internal" href="python_api/mlflow.html#mlflow.get_artifact_uri" title="mlflow.get_artifact_uri"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.get_artifact_uri()</span></code></a> returns the URI that artifacts from the current run should be
logged to.</p>
</div>
<div class="section" id="launching-multiple-runs-in-one-program">
<h3>Launching Multiple Runs in One Program<a class="headerlink" href="#launching-multiple-runs-in-one-program" title="Permalink to this headline"> </a></h3>
<p>Sometimes you want to execute multiple MLflow runs in the same program: for example, maybe you are
performing a hyperparameter search locally or your experiments are just very fast to run. This is
easy to do because the ActiveRun object returned by <a class="reference internal" href="python_api/mlflow.html#mlflow.start_run" title="mlflow.start_run"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.start_run()</span></code></a> is a Python
<a class="reference external" href="https://docs.python.org/2.5/whatsnew/pep-343.html">context manager</a>. You can “scope” each run to
just one block of code as follows:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_parameter</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>The run remains open throughout the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement, and is automatically closed when the
statement exits, even if it exits due to an exception.</p>
</div>
</div>
<div class="section" id="organizing-runs-in-experiments">
<h2>Organizing Runs in Experiments<a class="headerlink" href="#organizing-runs-in-experiments" title="Permalink to this headline"> </a></h2>
<p>MLflow allow you to group runs under experiments, which can be useful for comparing runs intended
to tackle a particular task. You can create experiments via the CLI (<code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">experiments</span></code>) or via
the <code class="xref py py-func docutils literal notranslate"><span class="pre">create_experiment()</span></code> Python API. You can pass the experiment ID for a individual run
via the CLI (for example, <code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">run</span> <span class="pre">...</span> <span class="pre">--experiment-id</span> <span class="pre">[ID]</span></code>) or via the <code class="docutils literal notranslate"><span class="pre">MLFLOW_EXPERIMENT_ID</span></code>
environment variable.</p>
<div class="code shell highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prints &quot;created an experiment with ID &lt;id&gt;</span>
<span class="n">mlflow</span> <span class="n">experiments</span> <span class="n">create</span> <span class="n">fraud</span><span class="o">-</span><span class="n">detection</span>
<span class="c1"># Set the ID via environment variables</span>
<span class="n">export</span> <span class="n">MLFLOW_EXPERIMENT_ID</span><span class="o">=&lt;</span><span class="nb">id</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Launch a run. The experiment ID is inferred from the MLFLOW_EXPERIMENT_ID environment</span>
<span class="c1"># variable, or from the --experiment-id parameter passed to the Databricks CLI (the latter</span>
<span class="c1"># taking precedence)</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_parameter</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="tracking-ui">
<span id="id1"></span><h2>Tracking UI<a class="headerlink" href="#tracking-ui" title="Permalink to this headline"> </a></h2>
<p>The Tracking UI lets you visualize, search and compare runs, as well as download run artifacts or
metadata for analysis in other tools. If you have been logging runs to a local <code class="docutils literal notranslate"><span class="pre">mlruns</span></code> directory,
simply run <code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">ui</span></code> in the directory above it, and it will load the corresponding runs.
Alternatively, the <a class="reference internal" href="#tracking-server"><span class="std std-ref">MLflow Server</span></a> serves the same UI, and enables remote storage of run artifacts.</p>
<p>The UI contains the following key features:</p>
<ul class="simple">
<li>Experiment-based run listing and comparison</li>
<li>Searching for runs by parameter or metric value</li>
<li>Visualizing run metrics</li>
<li>Downloading run results</li>
</ul>
</div>
<div class="section" id="querying-runs-programmatically">
<span id="tracking-query-api"></span><h2>Querying Runs Programmatically<a class="headerlink" href="#querying-runs-programmatically" title="Permalink to this headline"> </a></h2>
<p>All of the functions in the Tracking UI can be accessed programmatically through the
<a class="reference internal" href="python_api/mlflow.tracking.html#module-mlflow.tracking" title="mlflow.tracking"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mlflow.tracking</span></code></a> module and the REST API. This makes it easy to do several
common tasks:</p>
<ul class="simple">
<li>Query and compare runs using any data analysis tool of your choice, for example, <strong>pandas</strong>.</li>
<li>Determine the artifact URI for a run to feed some of its artifacts into a new run when executing
a workflow.</li>
<li>Load artifacts from past runs as <a class="reference internal" href="models.html#models"><span class="std std-ref">MLflow Models</span></a>.</li>
<li>Run automated parameter search algorithms, where you query the metrics from various runs to
submit new ones.</li>
</ul>
</div>
<div class="section" id="running-a-tracking-server">
<span id="tracking-server"></span><h2>Running a Tracking Server<a class="headerlink" href="#running-a-tracking-server" title="Permalink to this headline"> </a></h2>
<p>The MLflow tracking server launched via <code class="docutils literal notranslate"><span class="pre">mlflow</span> <span class="pre">server</span></code> also hosts REST APIs for tracking runs,
writing data to the local filesystem. You can specify a tracking server URI
via the <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_URI</span></code> environment variable and MLflow’s tracking APIs will automatically
communicate with the tracking server at that URI to create/get run information, log metrics, etc.</p>
<p>An example configuration for a server is as follows:</p>
<div class="code shell highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span> <span class="n">server</span> \
    <span class="o">--</span><span class="n">file</span><span class="o">-</span><span class="n">store</span> <span class="o">/</span><span class="n">mnt</span><span class="o">/</span><span class="n">persistent</span><span class="o">-</span><span class="n">disk</span> \
    <span class="o">--</span><span class="n">artifact</span><span class="o">-</span><span class="n">root</span> <span class="n">s3</span><span class="p">:</span><span class="o">//</span><span class="n">my</span><span class="o">-</span><span class="n">mlflow</span><span class="o">-</span><span class="n">bucket</span><span class="o">/</span> \
    <span class="o">--</span><span class="n">host</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span>
</pre></div>
</div>
<div class="section" id="storage">
<h3>Storage<a class="headerlink" href="#storage" title="Permalink to this headline"> </a></h3>
<p>There are two properties related to how data is stored:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--file-store</span></code> is where the server will store run and experiment information. This should
be a persistent (non-ephemeral) disk.</li>
<li><code class="docutils literal notranslate"><span class="pre">--artifact-root</span></code> causes clients to log their artifact output (e.g., models) to this
location which is suitable for large data (such as an S3 bucket or shared NFS file system). If
you do not provide this option, then clients will write artifacts to <em>their</em> local directories,
which the server probably can’t serve.</li>
</ul>
<p>Note that for the clients and server to access the artifact bucket, you should configure your Cloud
Provider credentials as normal. For example, S3 can be accessed by setting the <code class="docutils literal notranslate"><span class="pre">AWS_ACCESS_KEY_ID</span></code>
and <code class="docutils literal notranslate"><span class="pre">AWS_SECRET_ACCESS_KEY</span></code> environment variables, by using an IAM role, or by configuring a default
profile in <cite>~/.aws/credentials</cite>. See the <a class="reference external" href="https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup-credentials.html">AWS docs</a> for more info.</p>
</div>
<div class="section" id="networking">
<h3>Networking<a class="headerlink" href="#networking" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">--host</span></code> option exposes the service on all interfaces. If running a server in production, we
would recommend not exposing the built-in server broadly (as it is unauthenticated and unecrypted),
and instead putting it behind a reverse proxy like nginx or apache, or connecting over VPN.
Additionally, you should ensure that the <code class="docutils literal notranslate"><span class="pre">--file-store</span></code> (which defaults to the <code class="docutils literal notranslate"><span class="pre">./mlruns</span></code> directory)
points to a persistent (non-ephemeral) disk.</p>
</div>
<div class="section" id="connecting-to-a-remote-server">
<h3>Connecting to a Remote Server<a class="headerlink" href="#connecting-to-a-remote-server" title="Permalink to this headline"> </a></h3>
<p>Once you have a server running, simply set <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_URI</span></code> to the server’s URI, along
with its scheme and port (e.g., <code class="docutils literal notranslate"><span class="pre">http://10.0.0.1:5000</span></code>). Then you can use mlflow as normal:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">mlflow.start_run</span></code> and <code class="docutils literal notranslate"><span class="pre">mlflow.log_metric</span></code> calls make API requests to your remote
tracking server.</p>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="concepts.html" class="btn btn-neutral" title="Concepts" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="projects.html" class="btn btn-neutral" title="MLflow Projects" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2018. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'./',
      VERSION:'0.1.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      HAS_SOURCE:  true
    };
  </script>
  <script type="text/javascript" src="_static/jquery.js"></script>
  <script type="text/javascript" src="_static/underscore.js"></script>
  <script type="text/javascript" src="_static/doctools.js"></script>
  

  <script type="text/javascript" src="_static/js/zclipboard.min.js"></script>
  <script type="text/javascript" src="_static/js/jquery.waypoints.min.js"></script>

  
  
  <script type="text/javascript" src="_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-44077918-9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-44077918-9');
</script>


  
</body>
</html>