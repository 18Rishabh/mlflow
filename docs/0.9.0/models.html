
  

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MLflow Models &mdash; MLflow 0.9.0 documentation</title>
  
   
  <link rel="canonical" href="https://www.mlflow.org/docs/latest/models.html">
  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    

    

  
    
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-WXWDBL');</script>
      

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/css/algolia.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="MLflow 0.9.0 documentation" href="index.html"/>
        <link rel="next" title="Command-Line Interface" href="/cli.html"/>
        <link rel="prev" title="MLflow Projects" href="/projects.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="index.html" class="wy-nav-top-logo"><img src="_static/MLflow-logo-final-black.png" alt="MLFlow" /></a> <span class="version">0.9.0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  
  <input id="algolia-search" type="text" name="q" placeholder="Search" />
  
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="index.html" class="main-navigation-home"><img src="_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="projects.html">MLflow Projects</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MLflow Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#storage-format">Storage Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fields-in-the-mlmodel-format">Fields in the MLmodel Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-api">Model API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-model-flavors">Built-In Model Flavors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#python-function-python-function">Python Function (<code class="docutils literal"><span class="pre">python_function</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#h2o-h2o">H<sub>2</sub>O (<code class="docutils literal"><span class="pre">h2o</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#keras-keras">Keras (<code class="docutils literal"><span class="pre">keras</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mleap-mleap">MLeap (<code class="docutils literal"><span class="pre">mleap</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-pytorch">PyTorch (<code class="docutils literal"><span class="pre">pytorch</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scikit-learn-sklearn">Scikit-learn (<code class="docutils literal"><span class="pre">sklearn</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-mllib-spark">Spark MLlib (<code class="docutils literal"><span class="pre">spark</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow-tensorflow">TensorFlow (<code class="docutils literal"><span class="pre">tensorflow</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-customization">Model Customization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#custom-python-models">Custom Python Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-creating-a-custom-add-n-model">Example: Creating a custom “add n” model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-saving-an-xgboost-model-in-mlflow-format">Example: Saving an XGBoost model in MLflow format</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#custom-flavors">Custom Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-deployment-tools">Built-In Deployment Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deploy-a-python-function-model-as-a-local-rest-api-endpoint">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model as a local REST API endpoint</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#commands">Commands</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-a-python-function-model-on-microsoft-azure-ml">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Microsoft Azure ML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-a-python-function-model-on-amazon-sagemaker">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Amazon SageMaker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">Commands</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#export-a-python-function-model-as-an-apache-spark-udf">Export a <code class="docutils literal"><span class="pre">python_function</span></code> model as an Apache Spark UDF</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.rst" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>MLflow Models</li>
    
    
    <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/databricks/mlflow/blob/master/docs/source/models.rst" class="fa fa-github"> Edit on GitHub</a>
    </li>
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="mlflow-models">
<span id="models"></span><h1>MLflow Models<a class="headerlink" href="#mlflow-models" title="Permalink to this headline"> </a></h1>
<p>An MLflow Model is a standard format for packaging machine learning models that can be used in a
variety of downstream tools—for example, real-time serving through a REST API or batch inference
on Apache Spark. The format defines a convention that lets you save a model in different “flavors”
that can be understood by different downstream tools.</p>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title first">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#storage-format" id="id8">Storage Format</a></li>
<li><a class="reference internal" href="#model-api" id="id9">Model API</a></li>
<li><a class="reference internal" href="#built-in-model-flavors" id="id10">Built-In Model Flavors</a></li>
<li><a class="reference internal" href="#model-customization" id="id11">Model Customization</a></li>
<li><a class="reference internal" href="#built-in-deployment-tools" id="id12">Built-In Deployment Tools</a></li>
</ul>
</div>
<div class="section" id="storage-format">
<span id="model-storage-format"></span><h2><a class="toc-backref" href="#id8">Storage Format</a><a class="headerlink" href="#storage-format" title="Permalink to this headline"> </a></h2>
<p>Each MLflow Model is a directory containing arbitrary files, together with an <code class="docutils literal"><span class="pre">MLmodel</span></code>
file in the root of the directory that can define multiple <em>flavors</em> that the model can be viewed
in.</p>
<p>Flavors are the key concept that makes MLflow Models powerful: they are a convention that deployment
tools can use to understand the model, which makes it possible to write tools that work with models
from any ML library without having to integrate each tool with each library. MLflow defines
several “standard” flavors that all of its built-in deployment tools support, such as a “Python
function” flavor that describes how to run the model as a Python function. However, libraries can
also define and use other flavors. For example, MLflow’s <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a> library allows
loading models back as a scikit-learn <code class="docutils literal"><span class="pre">Pipeline</span></code> object for use in code that is aware of
scikit-learn, or as a generic Python function for use in tools that just need to apply the model
(for example, the <code class="docutils literal"><span class="pre">mlflow</span> <span class="pre">sagemaker</span></code> tool for deploying models to Amazon SageMaker).</p>
<p>All of the flavors that a particular model supports are defined in its <code class="docutils literal"><span class="pre">MLmodel</span></code> file in YAML
format. For example, <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a> outputs models as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span># Directory written by mlflow.sklearn.save_model(model, &quot;my_model&quot;)
my_model/
├── MLmodel
└── model.pkl
</pre></div>
</div>
<p>And its <code class="docutils literal"><span class="pre">MLmodel</span></code> file describes two flavors:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">time_created</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">2018-05-25T17:28:53.35</span>

<span class="l l-Scalar l-Scalar-Plain">flavors</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">sklearn</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">sklearn_version</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.19.1</span>
    <span class="l l-Scalar l-Scalar-Plain">pickled_model</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">model.pkl</span>
  <span class="l l-Scalar l-Scalar-Plain">python_function</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">loader_module</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">mlflow.sklearn</span>
</pre></div>
</div>
<p>This model can then be used with any tool that supports <em>either</em> the <code class="docutils literal"><span class="pre">sklearn</span></code> or
<code class="docutils literal"><span class="pre">python_function</span></code> model flavor. For example, the <code class="docutils literal"><span class="pre">mlflow</span> <span class="pre">sklearn</span></code> command can serve a
model with the <code class="docutils literal"><span class="pre">sklearn</span></code> flavor:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow sklearn serve my_model
</pre></div>
</div>
<p>In addition, the <code class="docutils literal"><span class="pre">mlflow</span> <span class="pre">sagemaker</span></code> command-line tool can package and deploy models to AWS
SageMaker as long as they support the <code class="docutils literal"><span class="pre">python_function</span></code> flavor:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow sagemaker deploy -m my_model <span class="o">[</span>other options<span class="o">]</span>
</pre></div>
</div>
<div class="section" id="fields-in-the-mlmodel-format">
<h3>Fields in the MLmodel Format<a class="headerlink" href="#fields-in-the-mlmodel-format" title="Permalink to this headline"> </a></h3>
<p>Apart from a <strong>flavors</strong> field listing the model flavors, the MLmodel YAML format can contain
the following fields:</p>
<dl class="docutils">
<dt>time_created</dt>
<dd>Date and time when the model was created, in UTC ISO 8601 format.</dd>
<dt>run_id</dt>
<dd>ID of the run that created the model, if the model was saved using <a class="reference internal" href="tracking.html#tracking"><span class="std std-ref">MLflow Tracking</span></a>.</dd>
</dl>
</div>
</div>
<div class="section" id="model-api">
<span id="id1"></span><h2><a class="toc-backref" href="#id9">Model API</a><a class="headerlink" href="#model-api" title="Permalink to this headline"> </a></h2>
<p>You can save and load MLflow Models in multiple ways. First, MLflow includes integrations with
several common libraries. For example, <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a> contains
<a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.save_model" title="mlflow.sklearn.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model</span></code></a>, <a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.log_model" title="mlflow.sklearn.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model</span></code></a>,
and <a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.load_model" title="mlflow.sklearn.load_model"><code class="xref py py-func docutils literal"><span class="pre">load_model</span></code></a> functions for scikit-learn models. Second,
you can use the <a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model" title="mlflow.models.Model"><code class="xref py py-class docutils literal"><span class="pre">mlflow.models.Model</span></code></a> class to create and write models. This
class has four key functions:</p>
<ul class="simple">
<li><a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.add_flavor" title="mlflow.models.Model.add_flavor"><code class="xref py py-func docutils literal"><span class="pre">add_flavor</span></code></a> to add a flavor to the model. Each flavor
has a string name and a dictionary of key-value attributes, where the values can be any object
that can be serialized to YAML.</li>
<li><a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.save" title="mlflow.models.Model.save"><code class="xref py py-func docutils literal"><span class="pre">save</span></code></a> to save the model to a local directory.</li>
<li><a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.log" title="mlflow.models.Model.log"><code class="xref py py-func docutils literal"><span class="pre">log</span></code></a> to log the model as an artifact in the
current run using MLflow Tracking.</li>
<li><a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.load" title="mlflow.models.Model.load"><code class="xref py py-func docutils literal"><span class="pre">load</span></code></a> to load a model from a local directory or
from an artifact in a previous run.</li>
</ul>
</div>
<div class="section" id="built-in-model-flavors">
<h2><a class="toc-backref" href="#id10">Built-In Model Flavors</a><a class="headerlink" href="#built-in-model-flavors" title="Permalink to this headline"> </a></h2>
<p>MLflow provides several standard flavors that might be useful in your applications. Specifically,
many of its deployment tools support these flavors, so you can export your own model in one of these
flavors to benefit from all these tools:</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#python-function-python-function" id="id13">Python Function (<code class="docutils literal"><span class="pre">python_function</span></code>)</a></li>
<li><a class="reference internal" href="#h2o-h2o" id="id14">H<sub>2</sub>O (<code class="docutils literal"><span class="pre">h2o</span></code>)</a></li>
<li><a class="reference internal" href="#keras-keras" id="id15">Keras (<code class="docutils literal"><span class="pre">keras</span></code>)</a></li>
<li><a class="reference internal" href="#mleap-mleap" id="id16">MLeap (<code class="docutils literal"><span class="pre">mleap</span></code>)</a></li>
<li><a class="reference internal" href="#pytorch-pytorch" id="id17">PyTorch (<code class="docutils literal"><span class="pre">pytorch</span></code>)</a></li>
<li><a class="reference internal" href="#scikit-learn-sklearn" id="id18">Scikit-learn (<code class="docutils literal"><span class="pre">sklearn</span></code>)</a></li>
<li><a class="reference internal" href="#spark-mllib-spark" id="id19">Spark MLlib (<code class="docutils literal"><span class="pre">spark</span></code>)</a></li>
<li><a class="reference internal" href="#tensorflow-tensorflow" id="id20">TensorFlow (<code class="docutils literal"><span class="pre">tensorflow</span></code>)</a></li>
</ul>
</div>
<div class="section" id="python-function-python-function">
<h3><a class="toc-backref" href="#id13">Python Function (<code class="docutils literal"><span class="pre">python_function</span></code>)</a><a class="headerlink" href="#python-function-python-function" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">python_function</span></code> model flavor defines a generic filesystem format for Python models and provides utilities
for saving and loading models to and from this format. The format is self-contained in the sense
that it includes all the information necessary to load and use a model. Dependencies
are stored either directly with the model or referenced via Conda environment.</p>
<p>Many MLflow Model persistence modules, such as <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a>, <a class="reference internal" href="python_api/mlflow.keras.html#module-mlflow.keras" title="mlflow.keras"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.keras</span></code></a>,
and <a class="reference internal" href="python_api/mlflow.pytorch.html#module-mlflow.pytorch" title="mlflow.pytorch"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch</span></code></a>, produce models with the <code class="docutils literal"><span class="pre">python_function</span></code> (<code class="docutils literal"><span class="pre">pyfunc</span></code>) flavor. This
means that they adhere to the <a class="reference internal" href="python_api/mlflow.pyfunc.html#pyfunc-filesystem-format"><span class="std std-ref">python_function filesystem format</span></a>
and can be interpreted as generic Python classes that implement the specified
<a class="reference internal" href="python_api/mlflow.pyfunc.html#pyfunc-inference-api"><span class="std std-ref">inference API</span></a>. Therefore, any tool that operates on these <code class="docutils literal"><span class="pre">pyfunc</span></code>
classes can operate on any MLflow Model containing the <code class="docutils literal"><span class="pre">pyfunc</span></code> flavor, regardless of which
persistence module or framework was used to produce the model. This interoperability is very
powerful because it allows any Python model to be productionized in a variety of environments.</p>
<p>The convention for <code class="docutils literal"><span class="pre">python_function</span></code> models is to have a <code class="docutils literal"><span class="pre">predict</span></code> method or function with the following
signature:</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="n">predict</span><span class="p">(</span><span class="n">model_input</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span> <span class="o">|</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span>
</pre></div>
</div>
<p>Other MLflow components expect <code class="docutils literal"><span class="pre">python_function</span></code> models to follow this convention.</p>
<p>The <code class="docutils literal"><span class="pre">python_function</span></code> <a class="reference internal" href="python_api/mlflow.pyfunc.html#pyfunc-filesystem-format"><span class="std std-ref">model format</span></a> is defined as a directory
structure containing all required data, code, and configuration.</p>
<p>The <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> module defines functions for saving and loading MLflow Models with the
<code class="docutils literal"><span class="pre">python_function</span></code> flavor. This module also includes utilities for creating custom Python models.
For more information, see the <a class="reference internal" href="#custom-python-models"><span class="std std-ref">custom Python models documentation</span></a>
and the <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> documentation.</p>
</div>
<div class="section" id="h2o-h2o">
<h3><a class="toc-backref" href="#id14">H<sub>2</sub>O (<code class="docutils literal"><span class="pre">h2o</span></code>)</a><a class="headerlink" href="#h2o-h2o" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">h2o</span></code> model flavor enables logging and loading H2O models.</p>
<p>The <a class="reference internal" href="python_api/mlflow.h2o.html#module-mlflow.h2o" title="mlflow.h2o"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.h2o</span></code></a> module defines <a class="reference internal" href="python_api/mlflow.h2o.html#mlflow.h2o.save_model" title="mlflow.h2o.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.h2o.html#mlflow.h2o.log_model" title="mlflow.h2o.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> methods for saving H2O models in MLflow Model format.
These methods produce MLflow Models with the <code class="docutils literal"><span class="pre">python_function</span></code> flavor, allowing you to load them
as generic Python functions for inference via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>. When you load
MLflow Models with the <code class="docutils literal"><span class="pre">h2o</span></code> flavor using <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">load_pyfunc()</span></code></a>,
the <a class="reference external" href="http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html#h2o.init">h2o.init()</a> method is
called. Therefore, the correct version of <code class="docutils literal"><span class="pre">h2o(-py)</span></code> must be installed in the loader’s
environment. You can customize the arguments given to
<a class="reference external" href="http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html#h2o.init">h2o.init()</a> by modifying the
<code class="docutils literal"><span class="pre">init</span></code> entry of the persisted H2O model’s YAML configuration file: <code class="docutils literal"><span class="pre">model.h2o/h2o.yaml</span></code>.</p>
<p>Finally, you can use the <a class="reference internal" href="python_api/mlflow.h2o.html#mlflow.h2o.load_model" title="mlflow.h2o.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.h2o.load_model()</span></code></a> method to load MLflow Models with the
<code class="docutils literal"><span class="pre">h2o</span></code> flavor as H2O model objects.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.h2o.html#module-mlflow.h2o" title="mlflow.h2o"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.h2o</span></code></a>.</p>
</div>
<div class="section" id="keras-keras">
<h3><a class="toc-backref" href="#id15">Keras (<code class="docutils literal"><span class="pre">keras</span></code>)</a><a class="headerlink" href="#keras-keras" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">keras</span></code> model flavor enables logging and loading Keras models. The <a class="reference internal" href="python_api/mlflow.keras.html#module-mlflow.keras" title="mlflow.keras"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.keras</span></code></a>
module defines <a class="reference internal" href="python_api/mlflow.keras.html#mlflow.keras.save_model" title="mlflow.keras.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.keras.html#mlflow.keras.log_model" title="mlflow.keras.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> functions that you can use to save Keras models
in MLflow Model format. These functions serialize Keras models as HDF5 files using the Keras
library’s built-in model persistence functions. MLflow Models produced by these functions
also contain the <code class="docutils literal"><span class="pre">python_function</span></code> flavor, allowing them to be interpreted as generic
Python functions for inference via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>. Finally, you can use
the <a class="reference internal" href="python_api/mlflow.keras.html#mlflow.keras.load_model" title="mlflow.keras.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.keras.load_model()</span></code></a> function to load MLflow Models with the
<code class="docutils literal"><span class="pre">keras</span></code> flavor as <a class="reference external" href="https://keras.io/models/about-keras-models/">Keras Model objects</a>.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.keras.html#module-mlflow.keras" title="mlflow.keras"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.keras</span></code></a>.</p>
</div>
<div class="section" id="mleap-mleap">
<h3><a class="toc-backref" href="#id16">MLeap (<code class="docutils literal"><span class="pre">mleap</span></code>)</a><a class="headerlink" href="#mleap-mleap" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">mleap</span></code> model flavor supports saving Spark models in MLflow format using the
<a class="reference external" href="http://mleap-docs.combust.ml/">MLeap</a> persistence mechanism. MLeap is an inference-optimized
format and execution engine for Spark models that does not depend on
<a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext">SparkContext</a>
to evaluate inputs.</p>
<p>You can save Spark models in MLflow format with the <code class="docutils literal"><span class="pre">mleap</span></code> flavor by specifying the
<code class="docutils literal"><span class="pre">sample_input</span></code> argument of the <a class="reference internal" href="python_api/mlflow.spark.html#mlflow.spark.save_model" title="mlflow.spark.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.spark.save_model()</span></code></a> or
<a class="reference internal" href="python_api/mlflow.spark.html#mlflow.spark.log_model" title="mlflow.spark.log_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.spark.log_model()</span></code></a> method (recommended). The <a class="reference internal" href="python_api/mlflow.mleap.html#module-mlflow.mleap" title="mlflow.mleap"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.mleap</span></code></a> module also
defines <a class="reference internal" href="python_api/mlflow.mleap.html#mlflow.mleap.save_model" title="mlflow.mleap.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.mleap.html#mlflow.mleap.log_model" title="mlflow.mleap.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> methods for saving MLeap models in MLflow format,
but these methods do not include the <code class="docutils literal"><span class="pre">python_function</span></code> flavor in the models they produce.</p>
<p>A companion module for loading MLflow Models with the MLeap flavor is available in the
<code class="docutils literal"><span class="pre">mlflow/java</span></code> package.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.spark.html#module-mlflow.spark" title="mlflow.spark"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.spark</span></code></a>, <a class="reference internal" href="python_api/mlflow.mleap.html#module-mlflow.mleap" title="mlflow.mleap"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.mleap</span></code></a>, and the
<a class="reference external" href="http://mleap-docs.combust.ml/">MLeap documentation</a>.</p>
</div>
<div class="section" id="pytorch-pytorch">
<h3><a class="toc-backref" href="#id17">PyTorch (<code class="docutils literal"><span class="pre">pytorch</span></code>)</a><a class="headerlink" href="#pytorch-pytorch" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">pytorch</span></code> model flavor enables logging and loading PyTorch models.</p>
<p>The <a class="reference internal" href="python_api/mlflow.pytorch.html#module-mlflow.pytorch" title="mlflow.pytorch"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch</span></code></a> module defines utilities for saving and loading MLflow Models with the
<code class="docutils literal"><span class="pre">pytorch</span></code> flavor. You can use the <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.save_model" title="mlflow.pytorch.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.log_model" title="mlflow.pytorch.log_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.log_model()</span></code></a> methods to save PyTorch models in MLflow format; both of these
functions use the <a class="reference external" href="https://pytorch.org/docs/stable/torch.html#torch.save">torch.save()</a> method to
serialize PyTorch models. Additionally, you can use the <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.load_model" title="mlflow.pytorch.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.load_model()</span></code></a>
method to load MLflow Models with the <code class="docutils literal"><span class="pre">pytorch</span></code> flavor as PyTorch model objects. Finally, models
produced by <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.save_model" title="mlflow.pytorch.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.save_model()</span></code></a> and <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.log_model" title="mlflow.pytorch.log_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.log_model()</span></code></a> contain
the <code class="docutils literal"><span class="pre">python_function</span></code> flavor, allowing you to load them as generic Python functions for inference
via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.pytorch.html#module-mlflow.pytorch" title="mlflow.pytorch"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch</span></code></a>.</p>
</div>
<div class="section" id="scikit-learn-sklearn">
<h3><a class="toc-backref" href="#id18">Scikit-learn (<code class="docutils literal"><span class="pre">sklearn</span></code>)</a><a class="headerlink" href="#scikit-learn-sklearn" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">sklearn</span></code> model flavor provides an easy-to-use interface for saving and loading scikit-learn
models. The <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a> module defines
<a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.save_model" title="mlflow.sklearn.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.log_model" title="mlflow.sklearn.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> functions that save scikit-learn models in
MLflow format, using either Python’s pickle module (Pickle) or CloudPickle for model serialization.
These functions produce MLflow Models with the <code class="docutils literal"><span class="pre">python_function</span></code> flavor, allowing them to
be loaded as generic Python functions for inference via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>.
Finally, you can use the <a class="reference internal" href="python_api/mlflow.sklearn.html#mlflow.sklearn.load_model" title="mlflow.sklearn.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.sklearn.load_model()</span></code></a> method to load MLflow Models with
the <code class="docutils literal"><span class="pre">sklearn</span></code> flavor as scikit-learn model objects.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.sklearn.html#module-mlflow.sklearn" title="mlflow.sklearn"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sklearn</span></code></a>.</p>
</div>
<div class="section" id="spark-mllib-spark">
<h3><a class="toc-backref" href="#id19">Spark MLlib (<code class="docutils literal"><span class="pre">spark</span></code>)</a><a class="headerlink" href="#spark-mllib-spark" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">spark</span></code> model flavor enables exporting Spark MLlib models as MLflow Models.</p>
<p>The <a class="reference internal" href="python_api/mlflow.spark.html#module-mlflow.spark" title="mlflow.spark"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.spark</span></code></a> module defines <a class="reference internal" href="python_api/mlflow.spark.html#mlflow.spark.save_model" title="mlflow.spark.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.spark.html#mlflow.spark.log_model" title="mlflow.spark.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> methods that save Spark MLlib pipelines in MLflow
model format. MLflow Models produced by these functions contain the <code class="docutils literal"><span class="pre">python_function</span></code> flavor,
allowing you to load them as generic Python functions via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>.
When a model with the <code class="docutils literal"><span class="pre">spark</span></code> flavor is loaded as a Python function via
<code class="xref py py-func docutils literal"><span class="pre">load_pyfunc()</span></code>, a new
<a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext">SparkContext</a>
is created for model inference; additionally, the function converts all Pandas DataFrame inputs to
Spark DataFrames before scoring. While this initialization overhead and format translation latency
is not ideal for high-performance use cases, it enables you to easily deploy any
<a class="reference external" href="http://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=pipelinemodel#pyspark.ml.Pipeline">MLlib PipelineModel</a> to any production environment supported by MLflow
(SageMaker, AzureML, etc).</p>
<p>Finally, the <a class="reference internal" href="python_api/mlflow.spark.html#mlflow.spark.load_model" title="mlflow.spark.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.spark.load_model()</span></code></a> method is used to load MLflow Models with
the <code class="docutils literal"><span class="pre">spark</span></code> flavor as Spark MLlib pipelines.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.spark.html#module-mlflow.spark" title="mlflow.spark"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.spark</span></code></a>.</p>
</div>
<div class="section" id="tensorflow-tensorflow">
<h3><a class="toc-backref" href="#id20">TensorFlow (<code class="docutils literal"><span class="pre">tensorflow</span></code>)</a><a class="headerlink" href="#tensorflow-tensorflow" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal"><span class="pre">tensorflow</span></code> model flavor allows serialized TensorFlow models in
<a class="reference external" href="https://www.tensorflow.org/guide/saved_model#save_and_restore_models">SavedModel format</a>
to be logged in MLflow format via the <a class="reference internal" href="python_api/mlflow.tensorflow.html#mlflow.tensorflow.save_model" title="mlflow.tensorflow.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.tensorflow.save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.tensorflow.html#mlflow.tensorflow.log_model" title="mlflow.tensorflow.log_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.tensorflow.log_model()</span></code></a> methods. These methods also add the <code class="docutils literal"><span class="pre">python_function</span></code>
flavor to the MLflow Models that they produce, allowing the models to be interpreted as generic
Python functions for inference via <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_pyfunc" title="mlflow.pyfunc.load_pyfunc"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pyfunc.load_pyfunc()</span></code></a>. Finally, you can use the
<a class="reference internal" href="python_api/mlflow.tensorflow.html#mlflow.tensorflow.load_model" title="mlflow.tensorflow.load_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.tensorflow.load_model()</span></code></a> method to load MLflow Models with the <code class="docutils literal"><span class="pre">tensorflow</span></code>
flavor as TensorFlow graphs.</p>
<p>For more information, see <a class="reference internal" href="python_api/mlflow.tensorflow.html#module-mlflow.tensorflow" title="mlflow.tensorflow"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.tensorflow</span></code></a>.</p>
</div>
</div>
<div class="section" id="model-customization">
<h2><a class="toc-backref" href="#id11">Model Customization</a><a class="headerlink" href="#model-customization" title="Permalink to this headline"> </a></h2>
<p>While MLflow’s built-in model persistence utilities are convenient for packaging models from various
popular ML libraries in MLflow Model format, they do not cover every use case. For example, you may
want to use a model from an ML library that is not explicitly supported by MLflow’s built-in
flavors. Alternatively, you may want to package custom inference code and data to create an
MLflow Model. Fortunately, MLflow provides two solutions that can be used to accomplish these
tasks: <a class="reference internal" href="#custom-python-models"><span class="std std-ref">Custom Python Models</span></a> and <a class="reference internal" href="#custom-flavors"><span class="std std-ref">Custom Flavors</span></a>.</p>
<div class="contents local topic" id="in-this-section">
<p class="topic-title first">In this section:</p>
<ul class="simple">
<li><a class="reference internal" href="#custom-python-models" id="id21">Custom Python Models</a><ul>
<li><a class="reference internal" href="#example-creating-a-custom-add-n-model" id="id22">Example: Creating a custom “add n” model</a></li>
<li><a class="reference internal" href="#example-saving-an-xgboost-model-in-mlflow-format" id="id23">Example: Saving an XGBoost model in MLflow format</a></li>
</ul>
</li>
<li><a class="reference internal" href="#custom-flavors" id="id24">Custom Flavors</a></li>
</ul>
</div>
<div class="section" id="custom-python-models">
<span id="id4"></span><h3><a class="toc-backref" href="#id21">Custom Python Models</a><a class="headerlink" href="#custom-python-models" title="Permalink to this headline"> </a></h3>
<p>The <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> module provides <a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.save_model" title="mlflow.pyfunc.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a> and
<a class="reference internal" href="python_api/mlflow.pyfunc.html#mlflow.pyfunc.log_model" title="mlflow.pyfunc.log_model"><code class="xref py py-func docutils literal"><span class="pre">log_model()</span></code></a> utilities for creating MLflow Models with the
<code class="docutils literal"><span class="pre">python_function</span></code> flavor that contain  user-specified code and <em>artifact</em> (file) dependencies.
These artifact dependencies may include serialized models produced by any Python ML library.</p>
<p>Because these custom models contain the <code class="docutils literal"><span class="pre">python_function</span></code> flavor, they can be deployed
to any of MLflow’s supported production environments, such as SageMaker, AzureML, or local
REST endpoints.</p>
<p>The following examples demonstrate how you can use the <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> module to create
custom Python models. For additional information about model customization with MLflow’s
<code class="docutils literal"><span class="pre">python_function</span></code> utilities, see the
<a class="reference internal" href="python_api/mlflow.pyfunc.html#pyfunc-create-custom"><span class="std std-ref">python_function custom models documentation</span></a>.</p>
<div class="section" id="example-creating-a-custom-add-n-model">
<h4><a class="toc-backref" href="#id22">Example: Creating a custom “add n” model</a><a class="headerlink" href="#example-creating-a-custom-add-n-model" title="Permalink to this headline"> </a></h4>
<p>This example defines a class for a custom model that adds a specified numeric value, <code class="docutils literal"><span class="pre">n</span></code>, to all
columns of a Pandas DataFrame input. Then, it uses the <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> APIs to save an
instance of this model with <code class="docutils literal"><span class="pre">n</span> <span class="pre">=</span> <span class="pre">5</span></code> in MLflow Model format. Finally, it loads the model in
<code class="docutils literal"><span class="pre">python_function</span></code> format and uses it to evaluate a sample input.</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow.pyfunc</span>

<span class="c1"># Define the model class</span>
<span class="k">class</span> <span class="nc">AddN</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model_input</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">column</span><span class="p">:</span> <span class="n">column</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># Construct and save the model</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;add_n_model&quot;</span>
<span class="n">add5_model</span> <span class="o">=</span> <span class="n">AddN</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">dst_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span> <span class="n">python_model</span><span class="o">=</span><span class="n">add5_model</span><span class="p">)</span>

<span class="c1"># Load the model in `python_function` format</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_pyfunc</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

<span class="c1"># Evaluate the model</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">model_input</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">model_output</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">model_output</span><span class="o">.</span><span class="n">equals</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">)]))</span>
</pre></div>
</div>
</div>
<div class="section" id="example-saving-an-xgboost-model-in-mlflow-format">
<h4><a class="toc-backref" href="#id23">Example: Saving an XGBoost model in MLflow format</a><a class="headerlink" href="#example-saving-an-xgboost-model-in-mlflow-format" title="Permalink to this headline"> </a></h4>
<p>This example begins by training and saving a gradient boosted tree model using the XGBoost
library. Next, it defines a wrapper class around the XGBoost model that conforms to MLflow’s
<code class="docutils literal"><span class="pre">python_function</span></code> <a class="reference internal" href="python_api/mlflow.pyfunc.html#pyfunc-inference-api"><span class="std std-ref">inference API</span></a>. Then, it uses the wrapper class and
the saved XGBoost model to construct an MLflow Model that performs inference using the gradient
boosted tree. Finally, it loads the MLflow Model in <code class="docutils literal"><span class="pre">python_function</span></code> format and uses it to
evaluate test data.</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="c1"># Load training and test datasets</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Train and save an XGBoost model</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="n">dtrain</span><span class="o">=</span><span class="n">dtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">xgb_model_path</span> <span class="o">=</span> <span class="s2">&quot;xgb_model.pth&quot;</span>
<span class="n">xgb_model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">xgb_model_path</span><span class="p">)</span>

<span class="c1"># Create an `artifacts` dictionary that assigns a unique name to the saved XGBoost model file.</span>
<span class="c1"># This dictionary will be passed to `mlflow.pyfunc.save_model`, which will copy the model file</span>
<span class="c1"># into the new MLflow Model&#39;s directory.</span>
<span class="n">artifacts</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;xgb_model&quot;</span><span class="p">:</span> <span class="n">xgb_model_path</span>
<span class="p">}</span>

<span class="c1"># Define the model class</span>
<span class="kn">import</span> <span class="nn">mlflow.pyfunc</span>
<span class="k">class</span> <span class="nc">XGBWrapper</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">load_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xgb_model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">artifacts</span><span class="p">[</span><span class="s2">&quot;xgb_model&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="n">input_matrix</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">model_input</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">)</span>

<span class="c1"># Create a Conda environment for the new MLflow Model that contains the XGBoost library</span>
<span class="c1"># as a dependency, as well as the required CloudPickle library</span>
<span class="kn">import</span> <span class="nn">cloudpickle</span>
<span class="n">conda_env</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;defaults&#39;</span><span class="p">],</span>
    <span class="s1">&#39;dependencies&#39;</span><span class="p">:</span> <span class="p">[</span>
      <span class="s1">&#39;xgboost={}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgb</span><span class="o">.</span><span class="n">__version__</span><span class="p">),</span>
      <span class="s1">&#39;cloudpickle={}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cloudpickle</span><span class="o">.</span><span class="n">__version__</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;xgb_env&#39;</span>
<span class="p">}</span>

<span class="c1"># Save the MLflow Model</span>
<span class="n">mlflow_pyfunc_model_path</span> <span class="o">=</span> <span class="s2">&quot;xgb_mlflow_pyfunc&quot;</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span>
        <span class="n">dst_path</span><span class="o">=</span><span class="n">mlflow_pyfunc_model_path</span><span class="p">,</span> <span class="n">python_model</span><span class="o">=</span><span class="n">XGBWrapper</span><span class="p">(),</span> <span class="n">artifacts</span><span class="o">=</span><span class="n">artifacts</span><span class="p">,</span>
        <span class="n">conda_env</span><span class="o">=</span><span class="n">conda_env</span><span class="p">)</span>

<span class="c1"># Load the model in `python_function` format</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_pyfunc</span><span class="p">(</span><span class="n">mlflow_pyfunc_model_path</span><span class="p">)</span>

<span class="c1"># Evaluate the model</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">test_predictions</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="custom-flavors">
<span id="id5"></span><h3><a class="toc-backref" href="#id24">Custom Flavors</a><a class="headerlink" href="#custom-flavors" title="Permalink to this headline"> </a></h3>
<p>You can also create custom MLflow Models by writing a custom <em>flavor</em>.</p>
<p>As discussed in the <a class="reference internal" href="#model-api"><span class="std std-ref">Model API</span></a> and <a class="reference internal" href="#model-storage-format"><span class="std std-ref">Storage Format</span></a> sections, an MLflow Model
is defined by a directory of files that contains an <code class="docutils literal"><span class="pre">MLmodel</span></code> configuration file. This <code class="docutils literal"><span class="pre">MLmodel</span></code>
file describes various model attributes, including the flavors in which the model can be
interpreted. The <code class="docutils literal"><span class="pre">MLmodel</span></code> file contains an entry for each flavor name; each entry is
a YAML-formatted collection of flavor-specific attributes.</p>
<p>To create a new flavor to support a custom model, you define the set of flavor-specific attributes
to include in the <code class="docutils literal"><span class="pre">MLmodel</span></code> configuration file, as well as the code that can interpret the
contents of the model directory and the flavor’s attributes.</p>
<p>As an example, let’s examine the <a class="reference internal" href="python_api/mlflow.pytorch.html#module-mlflow.pytorch" title="mlflow.pytorch"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch</span></code></a> module corresponding to MLflow’s
<code class="docutils literal"><span class="pre">pytorch</span></code> flavor. In the <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.save_model" title="mlflow.pytorch.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.save_model()</span></code></a> method, a PyTorch model is saved
to a specified output directory. Additionally, <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.save_model" title="mlflow.pytorch.save_model"><code class="xref py py-func docutils literal"><span class="pre">mlflow.pytorch.save_model()</span></code></a> leverages the
<a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.add_flavor" title="mlflow.models.Model.add_flavor"><code class="xref py py-func docutils literal"><span class="pre">mlflow.models.Model.add_flavor()</span></code></a> and <a class="reference internal" href="python_api/mlflow.models.html#mlflow.models.Model.save" title="mlflow.models.Model.save"><code class="xref py py-func docutils literal"><span class="pre">mlflow.models.Model.save()</span></code></a> functions to
produce an <code class="docutils literal"><span class="pre">MLmodel</span></code> configuration containing the <code class="docutils literal"><span class="pre">pytorch</span></code> flavor. The resulting configuration
has several flavor-specific attributes, such as <code class="docutils literal"><span class="pre">pytorch_version</span></code>, which denotes the version of the
PyTorch library that was used to train the model. To interpret model directories produced by
<a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.save_model" title="mlflow.pytorch.save_model"><code class="xref py py-func docutils literal"><span class="pre">save_model()</span></code></a>, the <a class="reference internal" href="python_api/mlflow.pytorch.html#module-mlflow.pytorch" title="mlflow.pytorch"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch</span></code></a> module also
defines a <a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.load_model" title="mlflow.pytorch.load_model"><code class="xref py py-mod docutils literal"><span class="pre">load_model()</span></code></a> method.
<a class="reference internal" href="python_api/mlflow.pytorch.html#mlflow.pytorch.load_model" title="mlflow.pytorch.load_model"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pytorch.load_model()</span></code></a> reads the <code class="docutils literal"><span class="pre">MLmodel</span></code> configuration from a specified
model directory and uses the configuration attributes of the <code class="docutils literal"><span class="pre">pytorch</span></code> flavor to load
and return a PyTorch model from its serialized representation.</p>
</div>
</div>
<div class="section" id="built-in-deployment-tools">
<h2><a class="toc-backref" href="#id12">Built-In Deployment Tools</a><a class="headerlink" href="#built-in-deployment-tools" title="Permalink to this headline"> </a></h2>
<p>MLflow provides tools for deploying models on a local machine and to several production environments.
Not all deployment methods are available for all model flavors. Deployment is supported for the
Python Function format and all compatible formats.</p>
<div class="contents local topic" id="id6">
<p class="topic-title first">In this section:</p>
<ul class="simple">
<li><a class="reference internal" href="#deploy-a-python-function-model-as-a-local-rest-api-endpoint" id="id25">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model as a local REST API endpoint</a></li>
<li><a class="reference internal" href="#deploy-a-python-function-model-on-microsoft-azure-ml" id="id26">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Microsoft Azure ML</a></li>
<li><a class="reference internal" href="#deploy-a-python-function-model-on-amazon-sagemaker" id="id27">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Amazon SageMaker</a></li>
<li><a class="reference internal" href="#export-a-python-function-model-as-an-apache-spark-udf" id="id28">Export a <code class="docutils literal"><span class="pre">python_function</span></code> model as an Apache Spark UDF</a></li>
</ul>
</div>
<div class="section" id="deploy-a-python-function-model-as-a-local-rest-api-endpoint">
<span id="pyfunc-deployment"></span><h3><a class="toc-backref" href="#id25">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model as a local REST API endpoint</a><a class="headerlink" href="#deploy-a-python-function-model-as-a-local-rest-api-endpoint" title="Permalink to this headline"> </a></h3>
<p>MLflow can deploy models locally as local REST API endpoints or to directly score CSV files.
This functionality is a convenient way of testing models before deploying to a remote model server.
You deploy the Python Function flavor locally using the CLI interface to the <a class="reference internal" href="python_api/mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.pyfunc</span></code></a> module.
The local REST API server accepts the following data formats as inputs:</p>
<ul class="simple">
<li>JSON-serialized pandas DataFrames in the <code class="docutils literal"><span class="pre">split</span></code> orientation. For example,
<code class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">pandas_df.to_json(orient='split')</span></code>. This format is specified using a <code class="docutils literal"><span class="pre">Content-Type</span></code>
request header value of <code class="docutils literal"><span class="pre">application/json</span></code> or <code class="docutils literal"><span class="pre">application/json;</span> <span class="pre">format=pandas-split</span></code>.</li>
<li>JSON-serialized pandas DataFrames in the <code class="docutils literal"><span class="pre">records</span></code> orientation. <em>We do not recommend using
this format because it is not guaranteed to preserve column ordering.</em> This format is
specified using a <code class="docutils literal"><span class="pre">Content-Type</span></code> request header value of
<code class="docutils literal"><span class="pre">application/json;</span> <span class="pre">format=pandas-records</span></code>.</li>
<li>CSV-serialized pandas DataFrames. For example, <code class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">pandas_df.to_csv()</span></code>. This format is
specified using a <code class="docutils literal"><span class="pre">Content-Type</span></code> request header value of <code class="docutils literal"><span class="pre">text/csv</span></code>.</li>
</ul>
<p>For more information about serializing pandas DataFrames, see
<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_json.html">pandas.DataFrame.to_json</a>.</p>
<div class="section" id="commands">
<h4>Commands<a class="headerlink" href="#commands" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><code class="xref py py-func docutils literal"><span class="pre">serve</span></code> deploys the model as a local REST API server.</li>
<li><code class="xref py py-func docutils literal"><span class="pre">predict</span></code> uses the model to generate a prediction for a local
CSV file.</li>
</ul>
<p>For more info, see:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow pyfunc --help
mlflow pyfunc serve --help
mlflow pyfunc predict --help
</pre></div>
</div>
</div>
</div>
<div class="section" id="deploy-a-python-function-model-on-microsoft-azure-ml">
<span id="azureml-deployment"></span><h3><a class="toc-backref" href="#id26">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Microsoft Azure ML</a><a class="headerlink" href="#deploy-a-python-function-model-on-microsoft-azure-ml" title="Permalink to this headline"> </a></h3>
<p>The <a class="reference internal" href="python_api/mlflow.azureml.html#module-mlflow.azureml" title="mlflow.azureml"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.azureml</span></code></a> module can package <code class="docutils literal"><span class="pre">python_function</span></code> models into Azure ML container images.
These images can be deployed to Azure Kubernetes Service (AKS) and the Azure Container Instances (ACI)
platform for real-time serving. The resulting Azure ML ContainerImage contains a web server that
accepts the following data formats as input:</p>
<ul class="simple">
<li>JSON-serialized pandas DataFrames in the <code class="docutils literal"><span class="pre">split</span></code> orientation. For example, <code class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">pandas_df.to_json(orient='split')</span></code>. This format is specified using a <code class="docutils literal"><span class="pre">Content-Type</span></code> request header value of <code class="docutils literal"><span class="pre">application/json</span></code>.</li>
<li><a class="reference internal" href="python_api/mlflow.azureml.html#mlflow.azureml.build_image" title="mlflow.azureml.build_image"><code class="xref py py-func docutils literal"><span class="pre">build_image</span></code></a> registers an MLflow Model with an existing Azure ML workspace and builds an Azure ML container image for deployment to AKS and ACI. The <a class="reference external" href="https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py">Azure ML SDK</a> is required in order to use this function. <em>The Azure ML SDK requires Python 3. It cannot be installed with earlier versions of Python.</em></li>
</ul>
<p class="rubric">Example workflow using the Python API</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow.azureml</span>

<span class="kn">from</span> <span class="nn">azureml.core</span> <span class="kn">import</span> <span class="n">Workspace</span>
<span class="kn">from</span> <span class="nn">azureml.core.webservice</span> <span class="kn">import</span> <span class="n">AciWebservice</span><span class="p">,</span> <span class="n">Webservice</span>


<span class="c1"># Create or load an existing Azure ML workspace. You can also load an existing workspace using</span>
<span class="c1"># Workspace.get(name=&quot;&lt;workspace_name&gt;&quot;)</span>
<span class="n">workspace_name</span> <span class="o">=</span> <span class="s2">&quot;&lt;Name of your Azure ML workspace&gt;&quot;</span>
<span class="n">subscription_id</span> <span class="o">=</span> <span class="s2">&quot;&lt;Your Azure subscription ID&gt;&quot;</span>
<span class="n">resource_group</span> <span class="o">=</span> <span class="s2">&quot;&lt;Name of the Azure resource group in which to create Azure ML resources&gt;&quot;</span>
<span class="n">location</span> <span class="o">=</span> <span class="s2">&quot;&lt;Name of the Azure location (region) in which to create Azure ML resources&gt;&quot;</span>
<span class="n">azure_workspace</span> <span class="o">=</span> <span class="n">Workspace</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
                                   <span class="n">subscription_id</span><span class="o">=</span><span class="n">subscription_id</span><span class="p">,</span>
                                   <span class="n">resource_group</span><span class="o">=</span><span class="n">resource_group</span><span class="p">,</span>
                                   <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
                                   <span class="n">create_resource_group</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                   <span class="n">exist_okay</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Build an Azure ML container image for deployment</span>
<span class="n">azure_image</span><span class="p">,</span> <span class="n">azure_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">azureml</span><span class="o">.</span><span class="n">build_image</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;&lt;path-to-model&gt;&quot;</span><span class="p">,</span>
                                                      <span class="n">workspace</span><span class="o">=</span><span class="n">azure_workspace</span><span class="p">,</span>
                                                      <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Wine regression model 1&quot;</span><span class="p">,</span>
                                                      <span class="n">synchronous</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># If your image build failed, you can access build logs at the following URI:</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Access the following URI for build logs: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">azure_image</span><span class="o">.</span><span class="n">image_build_log_uri</span><span class="p">))</span>

<span class="c1"># Deploy the container image to ACI</span>
<span class="n">webservice_deployment_config</span> <span class="o">=</span> <span class="n">AciWebservice</span><span class="o">.</span><span class="n">deploy_configuration</span><span class="p">()</span>
<span class="n">webservice</span> <span class="o">=</span> <span class="n">Webservice</span><span class="o">.</span><span class="n">deploy_from_image</span><span class="p">(</span>
                    <span class="n">image</span><span class="o">=</span><span class="n">azure_image</span><span class="p">,</span> <span class="n">workspace</span><span class="o">=</span><span class="n">azure_workspace</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&lt;deployment-name&gt;&quot;</span><span class="p">)</span>
<span class="n">webservice</span><span class="o">.</span><span class="n">wait_for_deployment</span><span class="p">()</span>

<span class="c1"># After the image deployment completes, requests can be posted via HTTP to the new ACI</span>
<span class="c1"># webservice&#39;s scoring URI. The following example posts a sample input from the wine dataset</span>
<span class="c1"># used in the MLflow ElasticNet example:</span>
<span class="c1"># https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Scoring URI is: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">webservice</span><span class="o">.</span><span class="n">scoring_uri</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># `sample_input` is a JSON-serialized pandas DataFrame with the `split` orientation</span>
<span class="n">sample_input</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;alcohol&quot;</span><span class="p">,</span>
        <span class="s2">&quot;chlorides&quot;</span><span class="p">,</span>
        <span class="s2">&quot;citric acid&quot;</span><span class="p">,</span>
        <span class="s2">&quot;density&quot;</span><span class="p">,</span>
        <span class="s2">&quot;fixed acidity&quot;</span><span class="p">,</span>
        <span class="s2">&quot;free sulfur dioxide&quot;</span><span class="p">,</span>
        <span class="s2">&quot;pH&quot;</span><span class="p">,</span>
        <span class="s2">&quot;residual sugar&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sulphates&quot;</span><span class="p">,</span>
        <span class="s2">&quot;total sulfur dioxide&quot;</span><span class="p">,</span>
        <span class="s2">&quot;volatile acidity&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">[</span><span class="mf">8.8</span><span class="p">,</span> <span class="mf">0.045</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">1.001</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">20.7</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">}</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
              <span class="n">url</span><span class="o">=</span><span class="n">webservice</span><span class="o">.</span><span class="n">scoring_uri</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">sample_input</span><span class="p">),</span>
              <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Content-type&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">})</span>
<span class="n">response_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">response_json</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Example workflow using the MLflow CLI</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow azureml build-image -w &lt;workspace-name&gt; -m &lt;model-path&gt; -d <span class="s2">&quot;Wine regression model 1&quot;</span>

az ml service create aci -n &lt;deployment-name&gt; --image-id &lt;image-name&gt;:&lt;image-version&gt;

<span class="c1"># After the image deployment completes, requests can be posted via HTTP to the new ACI</span>
<span class="c1"># webservice&#39;s scoring URI. The following example posts a sample input from the wine dataset</span>
<span class="c1"># used in the MLflow ElasticNet example:</span>
<span class="c1"># https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine</span>

<span class="nv">scoring_uri</span><span class="o">=</span><span class="k">$(</span>az ml service show --name &lt;deployment-name&gt; -v <span class="p">|</span> jq -r <span class="s2">&quot;.scoringUri&quot;</span><span class="k">)</span>

<span class="c1"># `sample_input` is a JSON-serialized pandas DataFrame with the `split` orientation</span>
<span class="nv">sample_input</span><span class="o">=</span><span class="s1">&#39;</span>
<span class="s1">{</span>
<span class="s1">    &quot;columns&quot;: [</span>
<span class="s1">        &quot;alcohol&quot;,</span>
<span class="s1">        &quot;chlorides&quot;,</span>
<span class="s1">        &quot;citric acid&quot;,</span>
<span class="s1">        &quot;density&quot;,</span>
<span class="s1">        &quot;fixed acidity&quot;,</span>
<span class="s1">        &quot;free sulfur dioxide&quot;,</span>
<span class="s1">        &quot;pH&quot;,</span>
<span class="s1">        &quot;residual sugar&quot;,</span>
<span class="s1">        &quot;sulphates&quot;,</span>
<span class="s1">        &quot;total sulfur dioxide&quot;,</span>
<span class="s1">        &quot;volatile acidity&quot;</span>
<span class="s1">    ],</span>
<span class="s1">    &quot;data&quot;: [</span>
<span class="s1">        [8.8, 0.045, 0.36, 1.001, 7, 45, 3, 20.7, 0.45, 170, 0.27]</span>
<span class="s1">    ]</span>
<span class="s1">}&#39;</span>

<span class="nb">echo</span> <span class="nv">$sample_input</span> <span class="p">|</span> curl -s -X POST <span class="nv">$scoring_uri</span><span class="se">\</span>
-H <span class="s1">&#39;Cache-Control: no-cache&#39;</span><span class="se">\</span>
-H <span class="s1">&#39;Content-Type: application/json&#39;</span><span class="se">\</span>
-d @-
</pre></div>
</div>
<p>For more info, see:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow azureml --help
mlflow azureml build-image --help
</pre></div>
</div>
</div>
<div class="section" id="deploy-a-python-function-model-on-amazon-sagemaker">
<span id="sagemaker-deployment"></span><h3><a class="toc-backref" href="#id27">Deploy a <code class="docutils literal"><span class="pre">python_function</span></code> model on Amazon SageMaker</a><a class="headerlink" href="#deploy-a-python-function-model-on-amazon-sagemaker" title="Permalink to this headline"> </a></h3>
<p>The <a class="reference internal" href="python_api/mlflow.sagemaker.html#module-mlflow.sagemaker" title="mlflow.sagemaker"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sagemaker</span></code></a> module can deploy <code class="docutils literal"><span class="pre">python_function</span></code> models locally in a Docker
container with SageMaker compatible environment and remotely on SageMaker.
To deploy remotely to SageMaker you need to set up your environment and user accounts.
To export a custom model to SageMaker, you need a MLflow-compatible Docker image to be available on Amazon ECR.
MLflow provides a default Docker image definition; however, it is up to you to build the image and upload it to ECR.
MLflow includes the utility function <code class="docutils literal"><span class="pre">build_and_push_container</span></code> to perform this step. Once built and uploaded, you can use the MLflow container for all MLflow Models. Model webservers deployed using the <a class="reference internal" href="python_api/mlflow.sagemaker.html#module-mlflow.sagemaker" title="mlflow.sagemaker"><code class="xref py py-mod docutils literal"><span class="pre">mlflow.sagemaker</span></code></a>
module accept the following data formats as input, depending on the deployment flavor:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">python_function</span></code>: For this deployment flavor, the endpoint accepts the same formats
as the pyfunc server. These formats are described in the
<a class="reference internal" href="#pyfunc-deployment"><span class="std std-ref">pyfunc deployment documentation</span></a>.</li>
<li><code class="docutils literal"><span class="pre">mleap</span></code>: For this deployment flavor, the endpoint accepts <cite>only</cite>
JSON-serialized pandas DataFrames in the <code class="docutils literal"><span class="pre">split</span></code> orientation. For example,
<code class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">pandas_df.to_json(orient='split')</span></code>. This format is specified using a <code class="docutils literal"><span class="pre">Content-Type</span></code>
request header value of <code class="docutils literal"><span class="pre">application/json</span></code>.</li>
</ul>
<div class="section" id="id7">
<h4>Commands<a class="headerlink" href="#id7" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><a class="reference internal" href="python_api/mlflow.sagemaker.html#mlflow.sagemaker.run_local" title="mlflow.sagemaker.run_local"><code class="xref py py-func docutils literal"><span class="pre">run-local</span></code></a> deploys the model locally in a Docker
container. The image and the environment should be identical to how the model would be run
remotely and it is therefore useful for testing the model prior to deployment.</li>
<li>The <code class="xref py py-func docutils literal"><span class="pre">build-and-push-container</span></code> CLI command builds an MLfLow
Docker image and uploads it to ECR. The caller must have the correct permissions set up. The image
is built locally and requires Docker to be present on the machine that performs this step.</li>
<li><a class="reference internal" href="python_api/mlflow.sagemaker.html#mlflow.sagemaker.deploy" title="mlflow.sagemaker.deploy"><code class="xref py py-func docutils literal"><span class="pre">deploy</span></code></a> deploys the model on Amazon SageMaker. MLflow
uploads the Python Function model into S3 and starts an Amazon SageMaker endpoint serving
the model.</li>
</ul>
<p class="rubric">Example workflow using the MLflow CLI</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow sagemaker build-and-push-container  - build the container <span class="o">(</span>only needs to be called once<span class="o">)</span>
mlflow sagemaker run-local -m &lt;path-to-model&gt;  - <span class="nb">test</span> the model locally
mlflow sagemaker deploy &lt;parameters&gt; - deploy the model remotely
</pre></div>
</div>
<p>For more info, see:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>mlflow sagemaker --help
mlflow sagemaker build-and-push-container --help
mlflow sagemaker run-local --help
mlflow sagemaker deploy --help
</pre></div>
</div>
</div>
</div>
<div class="section" id="export-a-python-function-model-as-an-apache-spark-udf">
<h3><a class="toc-backref" href="#id28">Export a <code class="docutils literal"><span class="pre">python_function</span></code> model as an Apache Spark UDF</a><a class="headerlink" href="#export-a-python-function-model-as-an-apache-spark-udf" title="Permalink to this headline"> </a></h3>
<p>You can output a <code class="docutils literal"><span class="pre">python_function</span></code> model as an Apache Spark UDF, which can be uploaded to a
Spark cluster and used to score the model.</p>
<p class="rubric">Example</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="n">pyfunc_udf</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">spark_udf</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">pyfunc_udf</span><span class="p">(</span><span class="o">&lt;</span><span class="n">features</span><span class="o">&gt;</span><span class="p">))</span>
</pre></div>
</div>
<p>The resulting UDF is based Spark’s Pandas UDF and is currently limited to producing either a single
value or an array of values of the same type per observation. By default, we return the first
numeric column as a double. You can control what result is returned by supplying <code class="docutils literal"><span class="pre">result_type</span></code>
argument. The following values are supported:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">'int'</span></code> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.IntegerType">IntegerType</a>: The leftmost integer that can fit in
<code class="docutils literal"><span class="pre">int32</span></code> result is returned or exception is raised if there is none.</li>
<li><code class="docutils literal"><span class="pre">'long'</span></code> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.LongType">LongType</a>: The leftmost long integer that can fit in <code class="docutils literal"><span class="pre">int64</span></code>
result is returned or exception is raised if there is none.</li>
<li><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.ArrayType">ArrayType</a> (<a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.IntegerType">IntegerType</a> | <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.LongType">LongType</a>): Return all integer columns that can fit
into the requested size.</li>
<li><code class="docutils literal"><span class="pre">'float'</span></code> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.FloatType">FloatType</a>: The leftmost numeric result cast to
<code class="docutils literal"><span class="pre">float32</span></code> is returned or exception is raised if there is no numeric column.</li>
<li><code class="docutils literal"><span class="pre">'double'</span></code> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.DoubleType">DoubleType</a>: The leftmost numeric result cast to
<code class="docutils literal"><span class="pre">double</span></code> is returned or exception is raised if there is no numeric column.</li>
<li><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.ArrayType">ArrayType</a> ( <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.FloatType">FloatType</a> | <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.DoubleType">DoubleType</a> ): Return all numeric columns cast to the
requested. type. Exception is raised if there are numeric columns.</li>
<li><code class="docutils literal"><span class="pre">'string'</span></code> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.StringType">StringType</a>: Result is the leftmost column converted to string.</li>
<li><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.ArrayType">ArrayType</a> ( <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.StringType">StringType</a> ): Return all columns converted to string.</li>
</ul>
<p class="rubric">Example</p>
<div class="highlight-py"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">ArrayType</span><span class="p">,</span> <span class="n">FloatType</span>
<span class="n">pyfunc_udf</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">spark_udf</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">result_type</span><span class="o">=</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">FloatType</span><span class="p">()))</span>
<span class="c1"># The prediction column will contain all the numeric columns returned by the model as floats</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">pyfunc_udf</span><span class="p">(</span><span class="o">&lt;</span><span class="n">features</span><span class="o">&gt;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="projects.html" class="btn btn-neutral" title="MLflow Projects" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="cli.html" class="btn btn-neutral" title="Command-Line Interface" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2019. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'./',
      VERSION:'0.9.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      HAS_SOURCE:  true
    };
  </script>
  <script type="text/javascript" src="_static/jquery.js"></script>
  <script type="text/javascript" src="_static/underscore.js"></script>
  <script type="text/javascript" src="_static/doctools.js"></script>
  <script type="text/javascript" src="_static/languagesections.js"></script>
  

  <script type="text/javascript" src="_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "_static/clippy.svg";</script>
  <script type="text/javascript" src="_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-44077918-9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-44077918-9');
</script>


  
    <!-- Algolia Search -->
    <script type="text/javascript">
      var algoliaConfigs = {
        key: 'b6d79a1058f2b3c1ee03bf659ade5a4b',
        index: 'mlflow',
      };
    </script>
    <div id="algolia-wrapper"></div>
    <script src="_static/js/tether.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
</body>
</html>